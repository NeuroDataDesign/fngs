{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big-graph generation\n",
    "\n",
    "In this demo, we will verify that our big-graph generation code is functioning properly on a small portion of a real DWI dataset that we can manually verify very easily. \n",
    "\n",
    "## Logic\n",
    "\n",
    "The logic of this function is essentially the same as that of the downsampling code written originally by Disa and Greg. The primary difference here is that, instead of looking for the ROI indices a particular voxel is part of, we instead this time define each voxel as its own index, and independently count streamlines for that particular voxel based on the Morton index of a given position.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "This approach has the advantage that it is purely data-derived, and the graph we end up with will be totally invertible since the only way a voxel ends up as part of the graph is by a streamline existing. By definition of a streamline, a streamline must be between two or more voxels, so then each point will be connected to some other point. \n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "This approach has the disadvantage that our ultimate graph will only have vertices if there exists a streamline linking the corresponding voxel of a given vertex to some other vertex. This means that small registration differences between subjects may lead to different vertex counts and different Morton indices corresponding to the same anatomical region due to that anatomical region being shifted by a voxel or two.\n",
    "\n",
    "We begin by running Greg's small demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: ndmg_demo-dwi\n",
      "Getting test data...\n",
      "Archive:  /tmp/small_demo.zip\n",
      "  inflating: small_demo/desikan.nii.gz  \n",
      "  inflating: small_demo/KKI2009_113_1_DTI_s4.bval  \n",
      "  inflating: small_demo/KKI2009_113_1_DTI_s4.bvec  \n",
      "  inflating: small_demo/KKI2009_113_1_DTI_s4.nii  \n",
      "  inflating: small_demo/KKI2009_113_1_MPRAGE_s4.nii  \n",
      "  inflating: small_demo/MNI152_T1_1mm_brain_mask_s4.nii.gz  \n",
      "  inflating: small_demo/MNI152_T1_1mm_s4.nii.gz  \n",
      "Creating output directory: /tmp/small_demo/outputs\n",
      "Creating output temp directory: /tmp/small_demo/outputs/tmp\n",
      "This pipeline will produce the following derivatives...\n",
      "DTI volume registered to atlas: /tmp/small_demo/outputs/reg_dwi/KKI2009_113_1_DTI_s4_aligned.nii.gz\n",
      "Diffusion tensors in atlas space: /tmp/small_demo/outputs/tensors/KKI2009_113_1_DTI_s4_tensors.npz\n",
      "Fiber streamlines in atlas space: /tmp/small_demo/outputs/fibers/KKI2009_113_1_DTI_s4_fibers.npz\n",
      "Graphs of streamlines downsampled to given labels: /tmp/small_demo/outputs/graphs/desikan/KKI2009_113_1_DTI_s4_desikan.gpickle\n",
      "Generating gradient table...\n",
      "B-values shape (17,)\n",
      "         min 0.000000 \n",
      "         max 700.000000 \n",
      "B-vectors shape (17, 3)\n",
      "         min -0.991788 \n",
      "         max 1.000000 \n",
      "None\n",
      "Aligning volumes...\n",
      "Executing: eddy_correct /tmp/small_demo/outputs/tmp/KKI2009_113_1_DTI_s4_t1.nii.gz /tmp/small_demo/outputs/tmp/KKI2009_113_1_DTI_s4_t1_t2.nii.gz 16\n",
      "Executing: bet /tmp/small_demo/KKI2009_113_1_MPRAGE_s4.nii /tmp/small_demo/outputs/tmp/KKI2009_113_1_MPRAGE_s4_ss.nii.gz -B\n",
      "Executing: epi_reg --epi=/tmp/small_demo/outputs/tmp/KKI2009_113_1_DTI_s4_t1_t2.nii.gz --t1=/tmp/small_demo/KKI2009_113_1_MPRAGE_s4.nii --t1brain=/tmp/small_demo/outputs/tmp/KKI2009_113_1_MPRAGE_s4_ss.nii.gz --out=/tmp/small_demo/outputs/tmp/KKI2009_113_1_DTI_s4_t1_ta.nii.gz\n",
      "Executing: flirt -in /tmp/small_demo/KKI2009_113_1_MPRAGE_s4.nii -ref /tmp/small_demo/MNI152_T1_1mm_s4.nii.gz -omat /tmp/small_demo/outputs/tmp/KKI2009_113_1_MPRAGE_s4_MNI152_T1_1mm_s4_xfm.mat -cost mutualinfo -bins 256 -dof 12 -searchrx -180 180 -searchry -180 180 -searchrz -180 180\n",
      "Executing: flirt -in /tmp/small_demo/outputs/tmp/KKI2009_113_1_DTI_s4_t1_ta.nii.gz -ref /tmp/small_demo/MNI152_T1_1mm_s4.nii.gz -out /tmp/small_demo/outputs/tmp/KKI2009_113_1_DTI_s4_t1_ta2.nii.gz -init /tmp/small_demo/outputs/tmp/KKI2009_113_1_MPRAGE_s4_MNI152_T1_1mm_s4_xfm.mat -interp trilinear -applyxfm\n",
      "Beginning tractography...\n",
      "Making Big Graph...\n",
      "# of Streamlines: 8906\n",
      "0\n",
      "445\n",
      "890\n",
      "1335\n",
      "1780\n",
      "2225\n",
      "2670\n",
      "3115\n",
      "3560\n",
      "4005\n",
      "4450\n",
      "4895\n",
      "5340\n",
      "5785\n",
      "6230\n",
      "6675\n",
      "7120\n",
      "7565\n",
      "8010\n",
      "8455\n",
      "8900\n",
      "Generating graph for desikan parcellation...\n",
      "{'ecount': 0, 'vcount': 70, 'region': 'brain', 'source': 'http://m2g.io', 'version': '0.0.50', 'date': 'Thu Aug  3 17:00:05 2017', 'sensor': 'Diffusion MRI', 'name': \"Generated by NeuroData's MRI Graphs (ndmg)\"}\n",
      "# of Streamlines: 8906\n",
      "0\n",
      "445\n",
      "890\n",
      "1335\n",
      "1780\n",
      "2225\n",
      "2670\n",
      "3115\n",
      "3560\n",
      "4005\n",
      "4450\n",
      "4895\n",
      "5340\n",
      "5785\n",
      "6230\n",
      "6675\n",
      "7120\n",
      "7565\n",
      "8010\n",
      "8455\n",
      "8900\n",
      "\n",
      " Graph Summary:\n",
      "Name: Generated by NeuroData's MRI Graphs (ndmg)\n",
      "Type: Graph\n",
      "Number of nodes: 70\n",
      "Number of edges: 773\n",
      "Average degree:  22.0857\n",
      "Execution took: 0:05:02.660297\n",
      "Complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ndmg\n",
    "import ndmg.utils as mgu\n",
    "\n",
    "# run small demo for experiments\n",
    "print(mgu.execute_cmd('ndmg_demo-dwi', verb=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach we will take is to take 2 fibers from our graph and verify that we end up with the appropriate voxels in our streamlines being connected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fibs = np.load('/tmp/small_demo/outputs/fibers/KKI2009_113_1_DTI_s4_fibers.npz')['arr_0']\n",
    "small_fibs = fibs[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ndmg.graph import biggraph as mgg\n",
    "from ndmg.graph.zindex import XYZMorton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Streamlines: 2\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "g1 = mgg()\n",
    "g1.make_graph(small_fibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "gra = nx.Graph()\n",
    "gra.add_weighted_edges_from(g1.edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should check to see that our graph ends up with the right number of vertices. We begin by looking at the floored values of the above voxel positions, since our image resolution is at 1mm scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "poss_vertices = set()  # use a set since we want unique elements\n",
    "streamlines = []\n",
    "for stream in small_fibs:\n",
    "    vertices = set()\n",
    "    for vertex in stream:\n",
    "        mid = str(XYZMorton(tuple(np.round(vertex))))  # morton index for vertex\n",
    "        vertices.add(mid)\n",
    "        poss_vertices.add(mid)\n",
    "    streamlines.append(vertices)\n",
    "print(len(poss_vertices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we see that there are 8 unique possible vertices, defining a vertex as a unique point in 3-dimensional space at 1mm resolution. We then can check out the number of unique vertices in our corresponding graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(gra.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We check that the voxel ids are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(poss_vertices == set(gra.nodes()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicating that our vertex indices appear to be correct. Let's check our streamlines to verify that the vertices each streamline is incident to are fully connected (and consequently have nonzero edge weight) in our resulting graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "edgect = 0  # count the number of edges we should have\n",
    "for stream in streamlines:\n",
    "    combns = combinations(stream, 2)  # stream is a list of vertices\n",
    "    for comb in combns:\n",
    "        edgect += 1\n",
    "        if gra.get_edge_data(*comb) == 0:  # check the particular combination\n",
    "            raise ValueError('Edge should exist that isnt in the graph!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't get any errors here, it is clear that every element that is in our graph should, in fact, be there. Using set notation, what we have shown is that:\n",
    "\n",
    "\\begin{align*}\n",
    "    A \\subseteq B\n",
    "\\end{align*}\n",
    "\n",
    "where $A$ is the set of edges that we expect to have, and $B$ is the set of edges that actually exist in our resulting graph. However, we also want to show that:\n",
    "\n",
    "\\begin{align*}\n",
    "    B \\subseteq A\n",
    "\\end{align*}\n",
    "\n",
    "so that we can conclude that $B = A$, or that our graph exactly matches the result we expect to end up with. To do this, we can simply check that the edges of $A$ are the *only* edges in $B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(edgect == .5*nx.to_numpy_matrix(gra).sum())  # multiply by 2 the expected count since the graph is directed\n",
    "                                                   # whereas the edgecount is undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
